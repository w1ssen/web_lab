# Webä¿¡æ¯å¤„ç†ä¸åº”ç”¨ lab1

## ç¬¬ä¸€é˜¶æ®µï¼šçˆ¬è™«&æ£€ç´¢

### ä¸€.çˆ¬è™«

#### å®éªŒè¦æ±‚ï¼š

1.å¯¹äºç”µå½±æ•°æ®ï¼Œè‡³å°‘çˆ¬å–å…¶åŸºæœ¬ä¿¡æ¯ã€å‰§æƒ…ç®€ä»‹ã€æ¼”èŒå‘˜è¡¨ï¼›é¼“åŠ±æŠ“å–æ›´å¤šæœ‰ç”¨ä¿¡æ¯ï¼ˆå¯èƒ½æœ‰ç›Šäºç¬¬2é˜¶æ®µçš„åˆ†æï¼‰ï¼›

2.å¯¹äºä¹¦ç±æ•°æ®ï¼Œè‡³å°‘çˆ¬å–å…¶åŸºæœ¬ä¿¡æ¯ã€å†…å®¹ç®€ä»‹ã€ä½œè€…ç®€ä»‹ï¼›é¼“åŠ±æŠ“å–æ›´å¤šæœ‰ç”¨ä¿¡æ¯ï¼ˆå¯èƒ½æœ‰ç›Šäºç¬¬2é˜¶æ®µçš„åˆ†æï¼‰ï¼›

3.çˆ¬è™«æ–¹å¼ä¸é™ï¼Œç½‘é¡µçˆ¬å–å’Œ API çˆ¬å–ä¸¤ç§æ–¹å¼éƒ½å¯ï¼Œä»‹ç»ä½¿ç”¨çš„çˆ¬è™«æ–¹å¼å·¥å…·ï¼›

4.é’ˆå¯¹æ‰€é€‰å–çš„çˆ¬è™«æ–¹å¼ï¼Œå‘ç°å¹¶åˆ†æå¹³å°çš„åçˆ¬æªæ–½ï¼Œå¹¶ä»‹ç»é‡‡ç”¨çš„åº”å¯¹ç­–ç•¥ï¼›

5.é’ˆå¯¹æ‰€é€‰å–çš„çˆ¬è™«æ–¹å¼ï¼Œä½¿ç”¨ä¸åŒçš„å†…å®¹è§£ææ–¹æ³•ï¼Œå¹¶æäº¤æ‰€è·å–çš„æ•°æ®ï¼›

6.è¯¥é˜¶æ®µæ— è¯„æµ‹æŒ‡æ ‡è¦æ±‚ï¼Œåœ¨å®éªŒæŠ¥å‘Šä¸­è¯´æ˜çˆ¬è™«ï¼ˆåçˆ¬ï¼‰ç­–ç•¥å’Œè§£ææ–¹æ³•å³å¯ã€‚

#### å®éªŒæ­¥éª¤

##### 1.çˆ¬å–é¡µé¢ï¼ˆ+åçˆ¬åº”å¯¹æªæ–½ï¼‰

åœ¨part1/web_scraper.pyæ–‡ä»¶ä¸­ä½¿ç”¨ python çš„ requests åº“ï¼Œç›´æ¥è¯·æ±‚å¯¹åº”çš„ urlæ¥è·å– html çš„å†…å®¹ã€‚

çˆ¬å–è¿‡ç¨‹ä¸­é€šè¿‡ç”Ÿæˆéšæœºipï¼Œæ‰‹åŠ¨æ·»åŠ æŠ¥å¤´ï¼Œæ·»åŠ cookiesï¼Œçˆ¬å–ä¼‘æ¯æ¥è§„é¿å¹³å°åçˆ¬

```python
# ç”Ÿæˆéšæœºip
def random_ip():
    ip = ".".join(str(random.randint(0, 255)) for _ in range(4))
    return ip
ip = random_ip()

# æ‰‹åŠ¨æ·»åŠ çš„æŠ¥å¤´ï¼Œç”¨äºè§„é¿è±†ç“£åçˆ¬(è®¿é—®ç½‘é¡µè¿”å›çŠ¶æ€ç 418)
headers = {
    'User-Agent':
    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36',
    'X-Forwarded-For':
    ip,
    'Cookie':
    'bid=HNf-ab2-lJI; gr_user_id=031667b7-5f8a-4ede-b695-e52d9181fe11; __gads=ID=60db1851df53b133:T=1583253085:S=ALNI_MbBwCgmPG1hMoA4-Z0HSw_zcT0a0A; _vwo_uuid_v2=DD32BB6F8D421706DCD1CDE1061FB7A45|ef7ec70304dd2cf132f1c42b3f0610e7; viewed="1200840_27077140_26943161_25779298"; ll="118165"; __yadk_uid=5OpXTOy4NkvMrHZo7Rq6P8VuWvCSmoEe; ct=y; ap_v=0,6.0; push_doumail_num=0; push_noty_num=0; _pk_ref.100001.4cf6=%5B%22%22%2C%22%22%2C1583508410%2C%22https%3A%2F%2Fwww.pypypy.cn%2F%22%5D; _pk_ses.100001.4cf6=*; dbcl2="131182631:x7xeSw+G5a8"; ck=9iia; _pk_id.100001.4cf6=17997f85dc72b3e8.1583492846.4.1583508446.1583505298.',
}

# çˆ¬å–ä¼‘æ¯
if __name__ == "__main__":
    ...
    delay = random.randint(0, 5)  # éšæœºé—´éš”0-5sè®¿é—®
    time.sleep(delay)
```

##### 2.å†…å®¹è§£æ

åœ¨part1/web_scraper.pyæ–‡ä»¶ä¸­ä½¿ç”¨BeautifulSoupè§£æé¡µé¢å†…å®¹ï¼Œä¹‹åæå–é¡µé¢ä¸­çš„å„ä¸ªä¿¡æ¯ã€‚ç”±äºé¡µé¢ä¸­çš„ä¿¡æ¯å¤§éƒ¨åˆ†æ˜¯è¿ç»­çš„textæ–‡æœ¬ï¼Œå¾ˆå¤šä¿¡æ¯ä¼šæ··åœ¨ä¸€èµ·ï¼Œé€šè¿‡å­—ç¬¦ä¸²åˆ‡å‰²æ¥è·å–éœ€è¦çš„ä¿¡æ¯ã€‚åŒæ—¶å› ä¸ºç½‘é¡µæ ¼å¼ä¸åŒï¼Œæœ‰çš„ç”µå½±/ä¹¦ç±å­˜åœ¨éƒ¨åˆ†æ•°æ®ç¼ºå¤±çš„æƒ…å†µï¼Œéœ€è¦æ·»åŠ åˆ¤æ–­è¯­å¥é¿å…ç¨‹åºæŠ¥é”™ã€‚

ä»¥è§£æç”µå½±å†…å®¹ä¸ºä¾‹ï¼š

```python
def search_douban_movie(id):
    ...
    # ä½¿ç”¨BeautifulSoupè§£æé¡µé¢å†…å®¹
    soup = BeautifulSoup(response.text, "html.parser")

    # æå–æœç´¢ç»“æœä¸­çš„ç”µå½±ä¿¡æ¯
    # è·å–ä¸­è‹±æ–‡åç§°
    temp = soup.find('span', {'property': 'v:itemreviewed'})
    if (temp is not None):
        name = temp.text
        # æˆªå–ä¸­æ–‡å
        chinese_name = name.split()[0]
        print('ä¸­æ–‡åç§°:', chinese_name)
        # æˆªå–å…¶ä»–åç§°
        if (name.split()[1:] != []):
            other_name = ' '.join(name.split()[1:])
            # print('å…¶ä»–åç§°:', other_name)
        else:
            other_name = None
    else:
        print("ç©ºé¡µé¢\n")
        return
  
    # è·å–å¹´ä»½
    temp = soup.find('span', class_='year')
    if (temp is not None):
        year = temp.text.strip()[1:5]
        # print('å¹´ä»½:', year)
    else:
        year = None

    # è·å–è¯„åˆ†
    temp = soup.find('strong', {'property': "v:average"})
    if (temp is not None):
        rate = temp.text
        # print('è¯„åˆ†:', rate)
    else:
        rate = None
  
    # è·å–å…¶ä»–ä¿¡æ¯
    info = soup.find('div', {'id': 'info'}).text

    # print(info[1:], '\n')
    index_1 = info.find('å¯¼æ¼”: ')
    index_2 = info.find('ç¼–å‰§: ')
    index_3 = info.find('ä¸»æ¼”: ')
    index_4 = info.find('ç±»å‹: ')
    index_5 = info.find('åˆ¶ç‰‡å›½å®¶/åœ°åŒº: ')
    index_6 = info.find('è¯­è¨€: ')
    index_7 = info.find('\n', index_6)
    if (index_1 != -1 and index_2 != -1):
        diretor = info[index_1 + len('å¯¼æ¼”: '):index_2 - 1]
        # print('å¯¼æ¼”:', diretor)
    else:
        diretor = None
    if (index_2 != -1 and index_3 != -1):
        scriptwriter = info[index_2 + len('ç¼–å‰§: '):index_3 - 1]
        # print('ç¼–å‰§:', scriptwriter)
    else:
        scriptwriter = None
    if (index_3 != -1 and index_4 != -1):
        actor = info[index_3 + len('ä¸»æ¼”: '):index_4 - 1]
        # print('ä¸»æ¼”:', actor)
    else:
        actor = None
    if (index_4 != -1 and index_5 != -1):
        type = info[index_4 + len('ç±»å‹: '):index_5 - 1]
        # print('ç±»å‹:', type)
    else:
        type = None
    if (index_5 != -1 and index_6 != -1):
        area = info[index_5 + len('åˆ¶ç‰‡å›½å®¶/åœ°åŒº: '):index_6 - 1]
        # print('åˆ¶ç‰‡å›½å®¶/åœ°åŒº:', area)
    else:
        area = None
    if (index_6 != -1 and index_7 != -1):
        language = info[index_6 + len('è¯­è¨€: '):index_7]
        # print('è¯­è¨€:', language)
    else:
        language = None
    detail = soup.find('span', {'class': 'all hidden'})  # å±•å¼€ç®€ä»‹
    if (detail is None):  # ä¸éœ€è¦å±•å¼€ç®€ä»‹
        detail = soup.find('span', {'property': 'v:summary'})
    detail = detail.text.strip().replace(' ', '')
    detail = detail.replace('\n\u3000\u3000', '')
    # print('ç®€ä»‹:\n', detail)
    print("=" * 40)

```

##### 3.å†…å®¹å†™å…¥

åœ¨part1/web_scraper.pyæ–‡ä»¶ä¸­ä½¿ç”¨pandasåº“ä¸­çš„æ•°æ®ç»“æ„DataFrameï¼Œå…ˆå°†çˆ¬å–çš„æ•°æ®è½¬åŒ–ä¸ºDataFrameç±»å‹ï¼Œç„¶åå°†æ•°æ®å†™å…¥åˆ°excelæ–‡æ¡£ã€‚

ä»¥ç”µå½±ä¸ºä¾‹ï¼š

```py
def search_douban_movie(id):
    ...
    global movie_list
    # ä¿¡æ¯å­—å…¸
    movie_list.append({
        "id": id,
        "cname": chinese_name,
        "ename": other_name,
        "year": year,
        "rate": rate,
        "director": diretor,
        "scr": scriptwriter,
        "star": actor,
        "type": type,
        "area": area,
        "lang": language,
        "syno": detail
    })
def movie_toExcel(data, fileName):  # pandasåº“å‚¨å­˜æ•°æ®åˆ°excel
    ids = []
    cnames = []
    enames = []
    years = []
    rates = []
    directors = []
    scrs = []
    stars = []
    types = []
    areas = []
    langs = []
    synos = []

    for i in range(len(data)):
        ids.append(data[i]["id"])
        cnames.append(data[i]["cname"])
        enames.append(data[i]["ename"])
        years.append(data[i]["year"])
        rates.append(data[i]["rate"])
        directors.append(data[i]["director"])
        scrs.append(data[i]["scr"])
        stars.append(data[i]["star"])
        types.append(data[i]["type"])
        areas.append(data[i]["area"])
        langs.append(data[i]["lang"])
        synos.append(data[i]["syno"])

    dfData = {  # ç”¨å­—å…¸è®¾ç½®DataFrameæ‰€éœ€æ•°æ®
        'åºå·': ids,
        'ä¸­æ–‡åç§°': cnames,
        'è‹±æ–‡åç§°': enames,
        'å¹´ä»½': years,
        'è¯„åˆ†': rates,
        'å¯¼æ¼”': directors,
        'ç¼–å‰§': scrs,
        'ä¸»æ¼”': stars,
        'ç±»å‹': types,
        'åˆ¶ç‰‡å›½å®¶/åœ°åŒº': areas,
        'è¯­è¨€': langs,
        'ç®€ä»‹': synos
    }

    df = pd.DataFrame(dfData)  # åˆ›å»ºDataFrame
    df.to_excel(fileName,
                index=False,
                sheet_name="{0}-{1}".format(LIST_POSITION, LIST_POSITION +
                                            LIST_SIZE))
```

å…·ä½“å†™å…¥æ—¶ï¼Œä¸ºäº†åˆ†æ®µå†™å…¥excelè¡¨æ ¼ï¼Œåšäº†ä»¥ä¸‹å¤„ç†ï¼š

```python
LIST_POSITION = 0 # è¯»å–çš„èµ·å§‹è¡Œæ•°
LIST_SIZE = 100 # ä¸€æ¬¡è¯»å–çš„è¡Œæ•°

book_list = []  # å­—å…¸åˆ—è¡¨
    count = 0
    times = 0
    for id in book_id_data:
        if (count < LIST_POSITION):
            count = count + 1
            continue
        if (times >= LIST_SIZE):
            break
        times = times + 1
        search_douban_book(id)
        book_toExcel(book_list, 'data/book.xlsx')
        delay = random.randint(0, 5)  # éšæœºé—´éš”0-5sè®¿é—®
        time.sleep(delay)
```

##### 4.å®éªŒç»“æœ

éƒ¨åˆ†å®éªŒç»“æœå¦‚ä¸‹ï¼Œå…¨éƒ¨ç»“æœè§æ–‡ä»¶part1/data/movie.xlsxå’Œæ–‡ä»¶part1/data/book.xlsxï¼ˆéƒ¨åˆ†é¡µé¢ä¸ºç©ºé¡µé¢ï¼Œç›´æ¥è·³è¿‡ï¼Œæ•…çˆ¬å–æ€»æ•°ä¸è¶³1200ï¼‰ã€‚

![image-20231030171146053](.\figs\image-20231030171146053.png)

![image-20231030171208270](.\figs\image-20231030171208270.png)

### äºŒ.æ£€ç´¢

#### å®éªŒè¦æ±‚ï¼š

1.å¯¹ä¸€é˜¶æ®µä¸­çˆ¬å–çš„ç”µå½±å’Œä¹¦ç±æ•°æ®è¿›è¡Œé¢„å¤„ç†ï¼Œå°†æ–‡æœ¬è¡¨å¾ä¸ºå…³é”®è¯é›†åˆã€‚

2.åœ¨ç»è¿‡é¢„å¤„ç†çš„æ•°æ®é›†ä¸Šå»ºç«‹å€’æ’ç´¢å¼•è¡¨ğ‘ºï¼Œå¹¶ä»¥åˆé€‚çš„æ–¹å¼å­˜å‚¨ç”Ÿæˆçš„å€’æ’ç´¢å¼•æ–‡ä»¶ã€‚

3.å¯¹äºç»™å®šçš„ bool æŸ¥è¯¢ğ‘¸ğ’ƒğ’ğ’ğ’ï¼ˆä¾‹å¦‚ åŠ¨ä½œ and å‰§æƒ…ï¼‰ï¼Œæ ¹æ®ä½ ç”Ÿæˆçš„å€’æ’ç´¢å¼•è¡¨ ğ‘ºï¼Œè¿”å›ç¬¦åˆæŸ¥è¯¢è§„åˆ™ğ‘¸ğ’ƒğ’ğ’ğ’çš„ç”µå½±æˆ–/å’Œä¹¦ç±é›†åˆğ‘¨ğ’ƒğ’ğ’ğ’ = {ğ‘¨ğ’ƒğ’ğ’ğ’, ğ‘¨ğ’ƒğ’ğ’ğ’, â€¦ }ï¼Œå¹¶ä»¥åˆé€‚çš„æ–¹å¼å±•ç°ç»™ç”¨æˆ·ï¼ˆä¾‹å¦‚ç»™å‡ºç”µå½±åç§°å’Œåˆ†ç±»æˆ–æ˜¾ç¤ºéƒ¨åˆ†ç®€ä»‹ç­‰ï¼‰ã€‚

4.ä»»é€‰ä¸€ç§è¯¾ç¨‹ä¸­ä»‹ç»è¿‡çš„ç´¢å¼•å‹ç¼©åŠ ä»¥å®ç°ï¼Œå¦‚æŒ‰å—å­˜å‚¨ã€å‰ç«¯ç¼–ç ç­‰ï¼Œå¹¶æ¯”è¾ƒå‹ç¼©åçš„ç´¢å¼•åœ¨å­˜å‚¨ç©ºé—´å’Œæ£€ç´¢æ•ˆç‡ä¸Šä¸åŸç´¢å¼•çš„åŒºåˆ«ã€‚

#### å®éªŒæ­¥éª¤ï¼š

##### 1.åˆ†è¯

åœ¨å¯¹ç”µå½±ç®€ä»‹/ä¹¦ç±ç®€ä»‹åˆ†è¯ç»“æŸå†™å…¥è¡¨æ ¼åï¼Œpart1/add_tag_to_keyå°†æä¾›çš„Tagä¹ŸåŠ å…¥åˆ°å…³é”®è¯ã€‚ä¸‹é¢ä»¥æ·»åŠ ç”µå½±Tagä¸ºä¾‹ï¼š

```python
# è·å–tagä¿¡æ¯ï¼Œå¹¶åŠ å…¥å…³é”®è¯
import pandas as pd
# è¯»å–æ–‡ä»¶å­˜å…¥åˆ—è¡¨å˜é‡
df1 = pd.read_csv('part1/data/Movie_tag.csv').fillna('')
movie_id_1 = df1['Id'].tolist()
movie_tag = df1['Tag'].tolist()
df2 = pd.read_excel('part1/data/movie.xlsx').fillna('')
movie_id_2 = df2['åºå·'].tolist()
# movie_type = df2['ç±»å‹'].tolist()
movie_id_key = df2['å…³é”®è¯'].tolist()
# å¾ªç¯æŸ¥æ‰¾éœ€è¦ä¿®æ”¹çš„åœ°æ–¹
for i in range(len(movie_id_2)):
    movie_id_key[i] = movie_id_key[i].replace(' ', '')

    # å¯¹æŒ‡å®šå•å…ƒæ ¼ä¿®æ”¹,æ–¹æ‹¬å·ä¸­çš„å‚æ•°ç¬¬ä¸€ä¸ªæ˜¯è¡Œå·ï¼Œç¬¬äºŒä¸ªæ˜¯åˆ—å
    df2.at[i, 'å…³é”®è¯'] = movie_id_key[i]
    # print(movie_id_key[index])
# å†™å›æ–‡ä»¶ï¼Œä¸€å®šä¸èƒ½å¿˜äº†è¿™ä¸€æ­¥
df2.to_excel('part1/data/movie.xlsx', index=False)
```

##### 2.å»ºç«‹å€’æ’è¡¨

åœ¨part1/in verted_index_to_excelä¸­ï¼Œå¯¹ç…§è·å–åˆ°çš„å…³é”®è¯ä¿¡æ¯ï¼Œé€šè¿‡pandasè¯»å–IDå’Œå¯¹åº”çš„å…³é”®è¯ï¼Œæ„å»ºå…³é”®è¯-IDå­—å…¸ï¼Œå†å°†å­—å…¸å†™å…¥excelè¡¨æ ¼ã€‚ä¸ºäº†æ–¹ä¾¿åç»­çš„Boolæ£€ç´¢ï¼ŒIDé‡‡ç”¨é›†åˆæ•°æ®ç»“æ„ã€‚ä»¥ç”µå½±ä¸ºä¾‹ï¼š

```python
import pandas as pd

df1 = pd.read_excel('part1/data/movie.xlsx').fillna('')
ids = df1['åºå·'].tolist()
keys = df1['å…³é”®è¯'].tolist()
Inverted_Index = dict()
id_list = []


# åˆ›å»ºå€’æ’è¡¨
def create_inverted_index():
    for i in range(len(keys)):
        keywords = keys[i].split(',')  # å°†æ¯ä¸ªidçš„å…³é”®è¯ç”¨é€—å·åˆ‡å‰²ï¼Œå˜æˆä¸€ä¸ªåˆ—è¡¨å˜é‡
        for item in keywords:  # éå†idçš„æ¯ä¸ªå…³é”®è¯
            if item not in Inverted_Index:
                Inverted_Index[item] = set()  # ä¸åœ¨å€’æ’è¡¨ä¸­çš„å…³é”®è¯æ–°å»ºé›†åˆ
            Inverted_Index[item].add(ids[i])  # åœ¨å€’æ’è¡¨å¯¹åº”çš„å…³é”®è¯ä½ç½®æ·»åŠ id
    for item in Inverted_Index:
        id_list.append({'key': item, 'id': Inverted_Index[item]})
    print(Inverted_Index)


def list_to_excel():
    keys = [item['key'] for item in id_list]
    ids = [item['id'] for item in id_list]
    dfData = {'å…³é”®è¯': keys, 'ID': ids}
    df = pd.DataFrame(dfData)  # åˆ›å»º DataFrame
    df.to_excel('part1/data/movie_list.xlsx', index=False)


create_inverted_index()
list_to_excel()
```

å€’æ’è¡¨ç»“æœè§part1/data/movie_listå’Œpart1/data/book_list

![image-20231030170747442](.\figs\image-20231030170747442.png)

![image-20231030171755887](.\figs\image-20231030171755887.png)

##### 3.å¸ƒå°”æŸ¥è¯¢

åœ¨part1/keyword_searchä¸­å®ç°äº†boolæ£€ç´¢ã€‚

é¦–å…ˆæ˜¯æ ¹æ®å¯¹æ£€ç´¢è¯­å¥è¿›è¡Œä¼˜å…ˆçº§ï¼Œå…³é”®è¯çš„åˆ†æã€‚æŒ‰ç…§boolæ£€ç´¢çš„è¿ç®—ç¬¦ä¼˜å…ˆçº§ï¼šæ‹¬å·>NOT>AND>ORï¼Œæ„å»ºå…³é”®è¯æ ˆå’Œè¿ç®—ç¬¦æ ˆï¼Œå…ˆè¿›è¡Œé«˜ä¼˜å…ˆçº§è¿ç®—ç¬¦çš„è®¡ç®—ã€‚å› ä¸ºä¸Šä¸€æ­¥é‡‡ç”¨äº†é›†åˆçš„æ•°æ®ç»“æ„å­˜å‚¨å€’æ’è¡¨ä¸­çš„IDï¼Œè¿™ä¸€æ­¥å¯¹è¿ç®—ç¬¦çš„å¤„ç†å°±å¯ä»¥ç›´æ¥è°ƒç”¨é›†åˆè¿ç®—äº†ã€‚

è€Œå¯¹äºå…³é”®è¯åœ¨å€’æ’è¡¨ä¸­çš„æŸ¥æ‰¾ï¼Œé‡‡ç”¨ç®€å•çš„åˆ—è¡¨æŸ¥è¯¢å°±å¥½ã€‚

```python
def search_in_movielist(search_input):
    # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æ¥åˆ†å‰²æŸ¥è¯¢å­—ç¬¦ä¸²
    tokens = re.split(r'(\(|\)|AND|OR|NOT)', search_input)

    # å®šä¹‰å¸ƒå°”æ“ä½œçš„å‡½æ•°
    def intersection(posting1, posting2):
        return set(posting1) & set(posting2)

    def union(posting1, posting2):
        return set(posting1) | set(posting2)

    def negation(posting):
        all_docs = set(movie_list_key)
        return all_docs - set(posting)

    stack = []
    operator_stack = []

    for token in tokens:
        token = token.strip()
        if token.strip() == "":
            continue
        if token == "(":
            operator_stack.append(token)
        elif token == ")":
            while operator_stack and operator_stack[-1] != "(":
                operator = operator_stack.pop()
                if operator == "AND":
                    operand2 = stack.pop()
                    operand1 = stack.pop()
                    stack.append(intersection(operand1, operand2))
                elif operator == "OR":
                    operand2 = stack.pop()
                    operand1 = stack.pop()
                    stack.append(union(operand1, operand2))
        elif token == "AND" or token == "OR":
            while operator_stack and operator_stack[-1] in (
                    "AND", "OR") and operator_stack[-1] != "(":
                operator = operator_stack.pop()
                operand2 = stack.pop()
                operand1 = stack.pop()
                if operator == "AND":
                    stack.append(intersection(operand1, operand2))
                elif operator == "OR":
                    stack.append(union(operand1, operand2))
            operator_stack.append(token)
        elif token == "NOT":
            operator_stack.append(token)
        else:
            # å¤„ç†å…³é”®è¯
            if token in movie_list_key:
                index = movie_list_key.index(token)
                stack.append(eval(movie_list_id[index]))
            else:
                stack.append(set())  # æœªçŸ¥è¯çš„ç»“æœä¸ºç©ºé›†

    while operator_stack:
        operator = operator_stack.pop()
        if operator == "AND" or operator == "OR":
            operand2 = stack.pop()
            operand1 = stack.pop()
            if operator == "AND":
                stack.append(intersection(operand1, operand2))
            elif operator == "OR":
                stack.append(union(operand1, operand2))
        elif operator == "NOT":
            operand = stack.pop()
            stack.append(negation(operand))
    print(stack[0])
    print_movie_info(stack[0])
```

å½“æ‰¾åˆ°éœ€è¦çš„idåï¼Œè¿˜éœ€è¦ä»¥åˆé€‚çš„å½¢å¼å‘ˆç°æœç´¢ç»“æœ

```python
# æ‰“å°æœç´¢å¾—åˆ°çš„idsçš„ç›¸å…³ä¿¡æ¯
def print_movie_info(ids):
    for id in ids:
        index = movie_id.index(id)  # æ‰¾åˆ°idçš„index
        print('ID:', id)
        print('ç”µå½±åç§°:', movie_name[index])
        print('ç”µå½±è¯„åˆ†:', movie_rate[index])
        print('ç”µå½±ç±»å‹:', movie_type[index])
        print('ç”µå½±ç®€ä»‹:', movie_info[index])
        print(40 * "=")
```

ä¸‹é¢æ˜¯æ£€ç´¢ç»“æœï¼š



##### 4.å¼•ç´¢å‹ç¼©

å› ä¸ºæ¶‰åŠåˆ°çš„å…³é”®è¯å¤šå¤§25000ä¸ªï¼Œè¿™ä¸ªè§„æ¨¡çš„å€’æ’è¡¨å¦‚æœæ”¾åœ¨å†…å­˜é‡Œå¾ˆå ç”¨ç©ºé—´ï¼Œä¸”ä¸åˆ©äºæ£€ç´¢ã€‚part1/inverted_index_zipé€šè¿‡åˆ†å—å­˜å‚¨å¯¹å€’æ’è¡¨è¿›è¡Œäº†å‹ç¼©ã€‚

åœ¨è¿™é‡Œå°†100ä¸ªå…³é”®è¯ä½œä¸ºä¸€ç»„ã€‚å½“ç»„æ»¡æ—¶ï¼Œç”Ÿæˆä¸€ä¸ªäºŒè¿›åˆ¶æ–‡ä»¶å­˜å‚¨å‹ç¼©çš„å€’æ’è¡¨ã€‚æœ€åç”Ÿæˆä¸€ä¸ªå…ƒæ•°æ®æŸ¥è¯¢è¡¨ï¼Œå°†å—å·å’Œå—å†…å­˜å‚¨çš„å…³é”®è¯è®°å½•åœ¨å…ƒæ•°æ®æŸ¥è¯¢è¡¨ä¸­ã€‚

```python
# æ¯100ä¸ªå…³é”®è¯ä¸ºä¸€ç»„ï¼Œæ„å»ºå‹ç¼©ç´¢å¼•è¡¨
def zip_inverted_index():
    # if os.path.exists('part1/data/block_metadata.pkl'):  # å­˜åœ¨å‹ç¼©çš„ç´¢å¼•è¡¨åï¼Œä¸å†æ„å»ºå‹ç¼©ç´¢å¼•è¡¨
    #     return
    df_movie_list = pd.read_excel('part1/data/movie_list.xlsx').fillna('')
    movie_list_key = df_movie_list['å…³é”®è¯'].tolist()
    movie_list_id = df_movie_list['ID'].tolist()
    block_size = 100  # å—çš„å¤§å°
    block_number = 0  # å—çš„ç¼–å·
    current_block = {}  # å½“å‰å—çš„å€’æ’ç´¢å¼•
    block_metadata = []  # å­˜å‚¨å—çš„å…ƒæ•°æ®ä¿¡æ¯
    for i in range(len(movie_list_id)):
        keyword = movie_list_key[i]
        current_block[keyword] = eval(movie_list_id[i])
        # current_block[keyword].add(eval(movie_list_id[i]))
        if len(current_block) >= block_size:
            block_number += 1
            block_filename = f"part1/block/block_{block_number}.pkl"  # æ–‡ä»¶åç¤ºä¾‹
            with open(block_filename, 'wb') as block_file:
                pickle.dump(current_block, block_file)
            block_metadata.append({
                'block_number': block_number,
                'keywords': list(current_block.keys())
            })
            current_block = {}
    for item in current_block:
        id_list.append({'key': item, 'id': current_block[item]})

    with open('part1/block_metadata.pkl', 'wb') as metadata_file:
        pickle.dump(block_metadata, metadata_file)

```

ä¸‹é¢éœ€è¦åˆ©ç”¨å‹ç¼©çš„å€’æ’è¡¨è¿›è¡Œæ£€ç´¢ã€‚å¯¹äºå…³é”®è¯keywordï¼Œéœ€è¦éå†å…ƒæ•°æ®æŸ¥è¯¢è¡¨ï¼Œæ‰¾åˆ°åæ‰“å¼€å¯¹åº”çš„å—ï¼Œå¹¶è¿”å›éœ€è¦çš„ID

```python
# å‹ç¼©ç´¢å¼•æ£€ç´¢
def search_in_zip(keyword):
    with open('part1/data/block_metadata.pkl', 'rb') as metadata_file:
        block_metadata = pickle.load(metadata_file)

    for block_info in block_metadata:
        block_filename = f"part1/block/block_{block_info['block_number']}.pkl"
        with open(block_filename, 'rb') as block_file:
            current_block = pickle.load(block_file)
            if keyword in current_block:
                # print(current_block[keyword])
                return current_block[keyword]
```

ä¸ºäº†ä½“ç°æ€§èƒ½å·®å¼‚ï¼Œåšå¦‚ä¸‹å¯¹æ¯”

```python
zip_inverted_index()
# æ£€ç´¢æ€§èƒ½è®¡æ—¶,ç´¢å¼•å‹ç¼©
start_time = time.time()
# æ¨¡æ‹Ÿæ£€ç´¢æ“ä½œ
keyword = "å®‰è¿ª"
search_in_zip(keyword)
keyword = "æ­¦å£«åˆ€"
search_in_zip(keyword)
keyword = "å¤§å±å¹•"
search_in_zip(keyword)
end_time = time.time()
elapsed_time = end_time - start_time
print(f"å‹ç¼©æ£€ç´¢ä»£ç è¿è¡Œæ—¶é—´: {elapsed_time} ç§’")

# æ£€ç´¢æ€§èƒ½è®¡æ—¶ï¼Œéå‹ç¼©

start_time = time.time()
# æ¨¡æ‹Ÿæ£€ç´¢æ“ä½œ
df_movie_list = pd.read_excel('part1/data/movie_list.xlsx').fillna('')
movie_list_key = df_movie_list['å…³é”®è¯'].tolist()
movie_list_id = df_movie_list['ID'].tolist()

keyword = "å®‰è¿ª"
search_in_list(keyword)
keyword = "æ­¦å£«åˆ€"
search_in_list(keyword)
keyword = "å¤§å±å¹•"
search_in_list(keyword)
end_time = time.time()
elapsed_time = end_time - start_time
print(f"é¡ºåºæ£€ç´¢ä»£ç è¿è¡Œæ—¶é—´: {elapsed_time} ç§’")
```

ç»“æœå¦‚ä¸‹ï¼š

![image-20231030174246161](.\figs\image-20231030174246161.png)

å¯¹äºåœ¨movieå€’æ’è¡¨ä¸­éšæœºé€‰å–çš„ä¸‰ä¸ªå…³é”®è¯ï¼Œé¡ºåºæ£€ç´¢èŠ±è´¹çš„æ—¶é—´æ˜¯è¿œè¿œå¤§äºå‹ç¼©æ£€ç´¢çš„ã€‚å½“æ£€ç´¢å…³é”®è¯å¢å¤šï¼Œè¿™ä¸ªå·®å¼‚ä¼šæ›´åŠ æ˜¾è‘—ã€‚è€Œä¸”å¦‚æœå°†å€’æ’è¡¨æ•´ä¸ªåŠ è½½åˆ°éå¸¸å ç”¨ç©ºé—´ã€‚è€Œå‹ç¼©ç´¢å¼•åï¼Œæ¯æ¬¡åªéœ€è¦æŠŠä¸€ä¸ªå—çš„æ•°æ®åŠ è½½åˆ°å†…å­˜ï¼Œé•¿æœŸå­˜åœ¨äºå†…å­˜ä¸­çš„åªæœ‰å…ƒæ•°æ®åˆ—è¡¨ï¼Œæå¤§åœ°èŠ‚çœäº†ç©ºé—´ã€‚

## ç¬¬äºŒé˜¶æ®µï¼šä½¿ç”¨è±†ç“£æ•°æ®è¿›è¡Œæ¨è

## æäº¤æ–‡ä»¶è¯´æ˜

```
â”œâ”€part1 # ç¬¬ä¸€é˜¶æ®µ
â”‚  â”‚  add_tag_to_keyword.py # å°†TagåŠ å…¥å…³é”®è¯
â”‚  â”‚  book_com.xlsx
â”‚  â”‚  inverted_index_to_excel.py # åˆ›å»ºå€’æ’è¡¨å¹¶å†™å…¥è¡¨æ ¼
â”‚  â”‚  inverted_index_zip.py # ç´¢å¼•å‹ç¼©,ä»¥åŠé¡ºåºç´¢å¼•å’Œå‹ç¼©ç´¢å¼•çš„æ€§èƒ½å¯¹æ¯”
â”‚  â”‚  jyc.txt
â”‚  â”‚  keyword_search.py # boolæ£€ç´¢
â”‚  â”‚  stop_words.txt
â”‚  â”‚  test_tyc.py
â”‚  â”‚  test_wordcut.py
â”‚  â”‚  tyc.py
â”‚  â”‚  web_scraper.py # çˆ¬è™«ï¼Œæœé›†ç”µå½±ä¹¦ç±ä¿¡æ¯
â”‚  â”‚  word_cut_jieba.py
â”‚  â”‚  word_cut_snownlp.py
â”‚  â”‚  ~$movie_list.xlsx
â”‚  â”‚
â”‚  â”œâ”€block # åˆ†å—å­˜å‚¨å¾—åˆ°çš„äºŒè¿›åˆ¶æ–‡ä»¶
â”‚  â””â”€data # ç›¸å…³æ•°æ®
â”‚          block_metadata.pkl # å‹ç¼©åçš„å€’æ’è¡¨
â”‚          book.xlsx # ä¹¦ç±çš„ç›¸å…³ä¿¡æ¯åŠå…³é”®è¯
â”‚          Book_id.csv # ä¹¦ç±ID
â”‚          book_list.xlsx # ä¹¦ç±å€’æ’è¡¨
â”‚          Book_tag.csv # ä¹¦ç±Tag
â”‚          movie.xlsx # ç”µå½±çš„ç›¸å…³ä¿¡æ¯åŠå…³é”®è¯
â”‚          Movie_id.csv # ç”µå½±ID
â”‚          movie_list.xlsx # ç”µå½±å€’æ’è¡¨
â”‚          Movie_tag.csv # ç”µå½±Tag
â”‚
â”œâ”€part2
â”‚  â”‚  graphrec.py
â”‚  â”‚  graph_rec_model.py
â”‚  â”‚  text_embedding.py
â”‚  â”‚  utils.py
â”‚  â”‚
â”‚  â””â”€data
â”‚          book_score.csv
â”‚          Contacts.txt
â”‚          movie_score.csv
â”‚          selected_book_top_1200_data_tag.csv
â”‚          selected_movie_top_1200_data_tag.csv
â”‚          tag_embedding_dict.pkl
â”‚
â”œâ”€report
â”‚  â”‚  report.md # æŠ¥å‘Š
â”‚  â”‚
â”‚  â””â”€figs #æŠ¥å‘Šä¸­çš„æ–‡ä»¶
â”œâ”€useless # ä¸­é—´æ•°æ®ä»¥åŠä¸€äº›æ•°æ®çš„å¤åˆ¶
â”‚      book.xlsx
â”‚      book_data.xlsx
â”‚      movie copy 2.xlsx
â”‚      movie_data.xlsx
â”‚      test.xlsx
â”‚
â””â”€__pycache__
        jb.cpython-310.pyc
        jieba.cpython-310.pyc
        tyc.cpython-310.pyc
        word_cut_jieba.cpython-310.pyc
```

